{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7213ed66",
   "metadata": {},
   "source": [
    "# File 09: Prediction Sentiment Analysis on Main Dataset\n",
    "\n",
    "### Input Files:\n",
    "- model-sa/model-gpu.yaml\n",
    "- model-sa/model-weights-gpu.h5\n",
    "- model-sa/tokenizer.pickle\n",
    "- db/04-main-data.csv\n",
    "- db/08-user-rating.csv\n",
    "\n",
    "### Output Files:\n",
    "- db/09-main-prediction.csv\n",
    "\n",
    "### Steps:\n",
    "1. loading required libraries\n",
    "1. loading model with weights\n",
    "1. loading the tokenizer\n",
    "1. loading main dataset\n",
    "1. dropping unnecessary rows\n",
    "1. prepping input for prediction\n",
    "1. predicting sentiment\n",
    "1. fetching user rating\n",
    "1. saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b715a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# loading required libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import model_from_yaml\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6be4ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artemis\\miniconda3\\envs\\project\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 48, 128)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 48, 196)           255584    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 48, 196)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 196)               308896    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 1,076,874\n",
      "Trainable params: 1,076,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading model with weights\n",
    "def load_model(model, weight) :\n",
    "    with open(model, 'r') as file:\n",
    "        yaml_model = file.read()\n",
    "\n",
    "    model = tf.keras.models.model_from_yaml(yaml_model)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.load_weights(weight)\n",
    "    return model\n",
    "\n",
    "model = load_model('sentiment-analysis-model/model-gpu.yaml', 'sentiment-analysis-model/weights-gpu.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4edeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer\n",
    "with open('sentiment-analysis-model/tokenizer.pickle', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4df4d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading main dataset\n",
    "df = pd.read_csv(\"db/04-main-data.csv\")\n",
    "rating = pd.read_csv(\"db/08-user-rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c887754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4912/4912 [00:05<00:00, 835.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# dropping unnecessary rows\n",
    "df_user = df.USER.values.tolist()\n",
    "rating_user = rating.USER.values.tolist()\n",
    "todrop_user = list(set(df_user) - set(rating_user))\n",
    "for name in tqdm(todrop_user) :\n",
    "    index = df.loc[df.USER == name].index\n",
    "    df.drop(index, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "613cd3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5863/5863 [00:02<00:00, 1986.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepping input for prediction\n",
    "df.TEXT=df.TEXT.astype(str)\n",
    "X = tokenizer.texts_to_sequences(df['TEXT'].values)\n",
    "X = pad_sequences(X, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8193c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting sentiment\n",
    "pred1 = []\n",
    "temp = model.predict(X)\n",
    "polarity = [round(value[1], 3) for value in temp]\n",
    "for value in polarity :\n",
    "    pred1.append(0 if value<0.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching user rating\n",
    "username = df.USER.values.tolist()\n",
    "user_rating = []\n",
    "for x in range(len(username)) :\n",
    "    user_rating.append(int(rating.loc[rating['USER'] == username[x]]['RATING']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9476d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving output\n",
    "final = pd.DataFrame(\n",
    "    list(zip(\n",
    "        df.USER.values.tolist(),\n",
    "        user_rating,\n",
    "        df.TEXT.values.tolist(),\n",
    "        df.ORIGINAL.values.tolist(),\n",
    "        df.SENTIMENT.values.tolist(),\n",
    "        polarity,\n",
    "        pred1)),\n",
    "    columns = [ 'USER', 'RATING', 'TEXT', 'ORIGINAL', 'SENTIMENT', 'OUTPUT', 'PRED1' ]\n",
    ")\n",
    "final.to_csv(\"db/09-phase-1-prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a80773",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(final.SENTIMENT.values.tolist(), final.PRED1.values.tolist())\n",
    "acc = accuracy_score(final.SENTIMENT.values.tolist(), final.PRED1.values.tolist())\n",
    "print(\"Printing Results:\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e39a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Major Project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
