{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944b6254",
   "metadata": {},
   "source": [
    "# File 05: Preprocessing User Timeline DataFrame\n",
    "\n",
    "This file does exactly what you think it does. Preprocessing and a lot of it. Firstly we need to make sure the tweets we feed into the model to run prediction on are in the correct format. We also decided to put a limit on the number of tweets a user should have. Here we are only considering users which have tweets in the range of 100 to 200 as it should give us more accuracy while predicting its accuracy. We also remove any tweets which have less than 3 words in it. \n",
    "\n",
    "### Input Files:\n",
    "- 03-user-tweets-english-only.csv\n",
    "\n",
    "### Output Files:\n",
    "- 05-shortlisted-tweets.csv\n",
    "- 05-shortlisted-usernames.csv\n",
    "\n",
    "### Steps:\n",
    "1. loading required libraries\n",
    "1. read user timeline tweets from dataframe\n",
    "1. create functions that will preprocess the dataset\n",
    "1. selecting only the tweets which have more than 2 words.\n",
    "1. making a list of all usernames\n",
    "1. counting tweets by each user\n",
    "1. shortlisting users with tweet count between 100 and 200\n",
    "1. making final list of tweets and users\n",
    "1. creating dataframes\n",
    "1. saving dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61e9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b131325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read user timeline tweets from dataframe\n",
    "\n",
    "df = pd.read_csv('db/03-user-tweets-english-only.csv')\n",
    "user = df.USER.values.tolist()\n",
    "tweet = df.TWEET.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433f466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions that will preprocess the dataset\n",
    "\n",
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "stopwords = set([\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"])\n",
    "\n",
    "def remove_single_chars(text) :\n",
    "    array = text.split()\n",
    "    return (\" \".join([w for w in array if len(w) > 1]))\n",
    "\n",
    "def remove_stopwords(text) :\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "def preprocess_text(sen) :\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('@[A-Za-z]+[A-Za-z0-9-_]+', '', sentence)\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub('/\\b\\S\\s\\b/', \"\", sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    sentence = remove_single_chars(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf63a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 953285/953285 [00:19<00:00, 48498.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# selecting only the tweets which have more than 2 words.\n",
    "\n",
    "user_new = []\n",
    "tweet_new = []\n",
    "\n",
    "for index in tqdm(range(len(df))):\n",
    "    text = preprocess_text(tweet[index])\n",
    "    if len(text.split()) > 2 :\n",
    "        user_new.append(user[index])\n",
    "        tweet_new.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b86aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 868770/868770 [00:33<00:00, 26087.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# making a list of all usernames\n",
    "\n",
    "username = []\n",
    "for x in tqdm(range(len(user_new))):\n",
    "    if user_new[x] not in username :\n",
    "        username.append(user_new[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33c0797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 9159/9159 [00:50<00:00, 181.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# counting tweets by each user\n",
    "\n",
    "np_user = np.array(user)\n",
    "tweetcount = []\n",
    "\n",
    "for searchval in tqdm(username) :\n",
    "    lst = list(np.where(np_user == searchval)[0])\n",
    "    tweetcount.append(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "186c7847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 9159/9159 [00:00<00:00, 3053221.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# shortlisting users with tweet count between 100 and 200\n",
    "\n",
    "shortlist = []\n",
    "for x in tqdm(range(len(username))) :\n",
    "    if (tweetcount[x] >= 100) and (tweetcount[x] <= 200) :\n",
    "        shortlist.append(username[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68de431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 868770/868770 [00:22<00:00, 38502.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# making final list of tweets and users\n",
    "\n",
    "final_user = []\n",
    "final_tweet = []\n",
    "\n",
    "for x in tqdm(range(len(user_new))) :\n",
    "    if user_new[x] in shortlist :\n",
    "        final_user.append(user_new[x])\n",
    "        final_tweet.append(tweet_new[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83175e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes\n",
    "\n",
    "final = pd.DataFrame(list(zip(final_user, final_tweet)), columns=['USER', 'TWEET'])\n",
    "username = pd.DataFrame(shortlist, columns=['USER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b5988fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframes\n",
    "\n",
    "final.to_csv('db/05-shortlisted-tweets.csv', index=False)\n",
    "username.to_csv('db/05-shortlisted-usernames.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_kernel",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
