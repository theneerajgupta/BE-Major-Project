{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7213ed66",
   "metadata": {},
   "source": [
    "# File 09: Prediction Sentiment Analysis on Main Dataset\n",
    "\n",
    "### Input Files:\n",
    "- model-sa/model-gpu.yaml\n",
    "- model-sa/model-weights-gpu.h5\n",
    "- model-sa/tokenizer.pickle\n",
    "- db/04-main-data.csv\n",
    "- db/08-user-rating.csv\n",
    "\n",
    "### Output Files:\n",
    "- db/09-main-prediction.csv\n",
    "\n",
    "### Steps:\n",
    "1. loading required libraries\n",
    "1. loading model with weights\n",
    "1. loading the tokenizer\n",
    "1. loading timeline tweets\n",
    "1. filter out tweets for which we dont have user rating\n",
    "1. combining everything into a dataset\n",
    "1. creating \"X\" input array \n",
    "1. using the model to predict sentiment of each tweet\n",
    "1. print accuracy of prediction\n",
    "1. creating final dataset\n",
    "1.saving dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b715a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# loading required libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import model_from_yaml\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6be4ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artemis\\miniconda3\\envs\\project\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 48, 128)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 48, 196)           255584    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 48, 196)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 196)               308896    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 1,076,874\n",
      "Trainable params: 1,076,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading model with weights\n",
    "def load_model(model, weight) :\n",
    "    with open(model, 'r') as file:\n",
    "        yaml_model = file.read()\n",
    "    \n",
    "    model = tf.keras.models.model_from_yaml(yaml_model)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.load_weights(weight)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_model('model-sa/model-gpu.yaml', 'model-sa/model-weights-gpu.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a4edeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer\n",
    "with open('model-sa/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4df4d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading timeline tweets\n",
    "df = pd.read_csv(\"db/04-main-data.csv\")\n",
    "user = pd.read_csv(\"db/08-user-rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c887754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4912/4912 [00:05<00:00, 835.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# filter out tweets for which we dont have user rating\n",
    "user_names = user.USER.values.tolist()\n",
    "user_rating = user.RATING.values.tolist()\n",
    "\n",
    "array = []\n",
    "for name in tqdm(user_names) :\n",
    "    for row in df.loc[df['USER'] == name].values.tolist() :\n",
    "        array.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "613cd3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5863/5863 [00:02<00:00, 1986.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# combining everything into a dataset\n",
    "users, tweet, sentiment, rating = [], [], [], []\n",
    "\n",
    "for row in tqdm(array) :\n",
    "    users.append(row[0])\n",
    "    tweet.append(row[1])\n",
    "    sentiment.append(row[2])\n",
    "    rating.append(int(user.loc[user['USER'] == row[0]]['RATING']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8193c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    list(zip(users, tweet, sentiment, rating)),\n",
    "    columns = ['USER', 'TWEET', 'SENTIMENT', 'RATING']\n",
    ")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ce19d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating \"X\" array \n",
    "X = tokenizer.texts_to_sequences(df['TWEET'].values)\n",
    "X = pad_sequences(X, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e20de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the model to predict sentiment of each tweet\n",
    "output = model.predict(X)\n",
    "prediction = model.predict_classes(X)\n",
    "truth = []\n",
    "for row in output:\n",
    "    truth.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "beb2e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735\n"
     ]
    }
   ],
   "source": [
    "# print accuracy of prediction\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(df['SENTIMENT'].values, prediction)\n",
    "accuracy = round((cm[0, 0] + cm[1, 1]) / len(df), 3)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6de51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating final dataset\n",
    "df = pd.DataFrame(\n",
    "    list(zip(users, tweet, sentiment, rating, prediction, truth)),\n",
    "    columns = ['USER', 'TWEET', 'SENTIMENT', 'RATING', 'PREDICTION', 'OUTPUT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "676c027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframes\n",
    "df.to_csv(\"db/09-main-prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa1ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_kernel",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
