{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711b6bd8",
   "metadata": {},
   "source": [
    "# Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "886d6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading all Libraries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Artemis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"# Loading all Libraries\")\n",
    "import re\n",
    "import nltk\n",
    "import tweepy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "from tweepy import OAuthHandler\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e7f80",
   "metadata": {},
   "source": [
    "# Loading Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b54ed007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loading model with weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artemis\\.conda\\envs\\project\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 48, 128)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 48, 196)           254800    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 48, 196)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               308112    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 1,203,306\n",
      "Trainable params: 1,203,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"# loading model with weights\")\n",
    "def load_model(model, weight) :\n",
    "    with open(model, 'r') as file:\n",
    "        yaml_model = file.read()\n",
    "\n",
    "    model = tf.keras.models.model_from_yaml(yaml_model)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.load_weights(weight)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = load_model('../sentiment-analysis-model/model-cpu.yaml', '../sentiment-analysis-model/weights-cpu.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605590dd",
   "metadata": {},
   "source": [
    "# Loading Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d568fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loading the tokenizer\n"
     ]
    }
   ],
   "source": [
    "print(\"# loading the tokenizer\")\n",
    "with open('../sentiment-analysis-model/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d5291",
   "metadata": {},
   "source": [
    "# Loading Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ac04f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load('../classification-model/clf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7a4ab",
   "metadata": {},
   "source": [
    "# Setting Up Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2b3461b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication Successful!\n"
     ]
    }
   ],
   "source": [
    "consumer_key = 'e3quFb7yTv8RJBfJtcsH172ey'\n",
    "consumer_secret =  'SI8hYfTDQ6t90DVzk8saJlbp3Frz9eo0IWW9qCBK5JzgLj4ofa'\n",
    "access_token = '724078891384582144-KG0kZkal2PbRFiXOQva8Uatull9qVRx'\n",
    "access_token_secret = 'JWZlsm0KYB4vkjzc2CuJOkVaoym0L2Ts2lK9bBhSRMm3t'\n",
    "\n",
    "try :\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    print(\"Authentication Successful!\")\n",
    "except :\n",
    "    print(\"Authentication Failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bcf88",
   "metadata": {},
   "source": [
    "# Class to Fetch Timeline Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "92dcf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter_User():\n",
    "    def __init__(self,username,count=200):\n",
    "        self.id = api.get_user(username).id\n",
    "        self.username = username\n",
    "        self.count = count\n",
    "        self.data = None\n",
    "\n",
    "    def get_tweets(self):\n",
    "        store_tweets = api.user_timeline(self.id, count=self.count)\n",
    "        simple_list = []\n",
    "        for status in store_tweets:\n",
    "            array = [status._json[\"text\"].strip()]\n",
    "            simple_list.append(array)\n",
    "\n",
    "        self.data = pd.DataFrame(simple_list, columns=[\"TEXT\"])\n",
    "        self.data = self.data[~self.data[\"TEXT\"].str.startswith('RT')]\n",
    "        return self.data\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        id = api.get_user(self.id)\n",
    "        return id.screen_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f07b12",
   "metadata": {},
   "source": [
    "# Function to process input URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "074a445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(url) :\n",
    "    url = re.findall('http[s]?://twitter.com/(?:[a-zA-Z]|[0-9])+/status/[0-9]+', url)\n",
    "    try :\n",
    "        url = url[0].split(\"/\")\n",
    "        user_id = url[3]\n",
    "        tweet_id = url[5]\n",
    "        return (user_id, tweet_id)\n",
    "    except :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719681e",
   "metadata": {},
   "source": [
    "# Function to Fetch Tweet/User Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a8da6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_info(url) :\n",
    "    tweet = api.get_status(process_url(url)[1])\n",
    "    \n",
    "    tweet_keys = ['created_at', 'id', 'text', 'retweet_count', 'favorite_count']\n",
    "    tweet_values = []\n",
    "    for key in tweet_keys :\n",
    "        tweet_values.append(tweet._json[key])\n",
    "\n",
    "    user_keys = ['id', 'name', 'screen_name', 'url', 'description', 'followers_count', 'friends_count', 'profile_image_url_https']\n",
    "    user_values = []\n",
    "    for key in user_keys :\n",
    "        user_values.append(tweet._json['user'][key])\n",
    "\n",
    "    tweet_info = dict(zip(tweet_keys, tweet_values))\n",
    "    user_info = dict(zip(user_keys, user_values))\n",
    "    \n",
    "    return (user_info, tweet_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9549f9",
   "metadata": {},
   "source": [
    "# Functions to Preprocess Timeline Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "256db2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "sw = stopwords.words('english')\n",
    "sw.remove('not')\n",
    "\n",
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def remove_single_chars(text) :\n",
    "    array = text.split()\n",
    "    return (\" \".join([w for w in array if len(w) > 1]))\n",
    "\n",
    "def remove_stopwords(text) :\n",
    "    text = \" \".join([word for word in text.split() if word not in sw])\n",
    "    return text\n",
    "\n",
    "def apply_stemming(text) :\n",
    "    arr1 = text.split(\" \")\n",
    "    arr2 = []\n",
    "    for word in arr1 :\n",
    "        arr2.append(porter.stem(word))\n",
    "    text = \" \".join(arr2)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(sen) :\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('@[A-Za-z]+[A-Za-z0-9-_]+', '', sentence)\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    sentence = remove_single_chars(sentence)\n",
    "    sentence = apply_stemming(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d73af1",
   "metadata": {},
   "source": [
    "# Function to Calculate User Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "31850ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating(user_screen_name) :\n",
    "    user = Twitter_User(user_screen_name) \n",
    "    tweets = list(user.get_tweets().TEXT.values.tolist())\n",
    "    \n",
    "    # preprocess all tweets\n",
    "    preprocessed = []\n",
    "    for sent in tweets :\n",
    "        preprocessed.append(preprocess_text(sent))\n",
    "        \n",
    "    # tokenize and pad all tweets\n",
    "    X = tokenizer.texts_to_sequences(preprocessed)\n",
    "    X = pad_sequences(X, 48)\n",
    "    \n",
    "    # predict sentiment\n",
    "    pred = model.predict(X)\n",
    "    prediction = []\n",
    "    for value in pred :\n",
    "        prediction.append(value[1])\n",
    "        \n",
    "    # calculate rating :\n",
    "    score = 0\n",
    "    for value in prediction :\n",
    "        if value < 0.3 :\n",
    "            score = score - 1\n",
    "        elif value > 0.7 :\n",
    "            score = score + 1\n",
    "    \n",
    "    return 0 if score < 0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556892ca",
   "metadata": {},
   "source": [
    "# Fuction to Predcit Sentiment of Original Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "228623d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tweet) :\n",
    "    X = tokenizer.texts_to_sequences([tweet])\n",
    "    X = pad_sequences(X, 48)\n",
    "    prediction = model.predict(X)[0][1]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912521b4",
   "metadata": {},
   "source": [
    "# Calculate Sentence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d6e6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv(\"../../db/10-positive-word-score.csv\")\n",
    "neg = pd.read_csv(\"../../db/10-negative-word-score.csv\")\n",
    "lst = pos.values.tolist()\n",
    "for row in neg.values.tolist() :\n",
    "    lst.append(row)\n",
    "    \n",
    "dictionary = dict(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d62e8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sent_score(text) :\n",
    "    arr = text.split(\" \")\n",
    "    score = 0\n",
    "    for word in arr :\n",
    "        if word in dictionary :\n",
    "            score = score + dictionary[word]\n",
    "            \n",
    "    return 0 if score < 0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9cb8d",
   "metadata": {},
   "source": [
    "# Fetching User & Tweet Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ebcc1",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "91313fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url) :\n",
    "    user, tweet = tweet_info(url)\n",
    "    userid = user['screen_name']\n",
    "    text = tweet['text']\n",
    "    newtext = preprocess_text(tweet['text'])\n",
    "    \n",
    "    prediction = sentiment(pp_tweet)\n",
    "    rating = calculate_rating(userid)\n",
    "    score = calculate_sent_score(pp_tweet)\n",
    "    \n",
    "    df = pd.DataFrame([[prediction, rating, score]])\n",
    "    prediction = classifier.predict(ip)[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c26c83f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(\"https://twitter.com/WorstInvestor2/status/1395045485195505667?s=20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15d7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Major Project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
