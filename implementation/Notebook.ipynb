{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e382293f",
   "metadata": {},
   "source": [
    "# Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886d6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading all Libraries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Artemis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"# Loading all Libraries\")\n",
    "import re\n",
    "import nltk\n",
    "import tweepy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tweepy import OAuthHandler\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094f35d",
   "metadata": {},
   "source": [
    "# Loading Main Machine Learning Models + Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54ed007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artemis\\.conda\\envs\\project\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loading model with weights\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 48, 128)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 48, 196)           254800    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 48, 196)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               308112    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 1,203,306\n",
      "Trainable params: 1,203,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"# loading model with weights\")\n",
    "def load_model(model, weight) :\n",
    "    with open(model, 'r') as file:\n",
    "        yaml_model = file.read()\n",
    "\n",
    "    model = tf.keras.models.model_from_yaml(yaml_model)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.load_weights(weight)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = load_model('../sentiment-analysis-model/model-cpu.yaml', '../sentiment-analysis-model/weights-cpu.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d568fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loading the tokenizer\n"
     ]
    }
   ],
   "source": [
    "print(\"# loading the tokenizer\")\n",
    "with open('../sentiment-analysis-model/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926ae02",
   "metadata": {},
   "source": [
    "# Loading Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fe6b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>USER</th>\n",
       "      <th>ORIGINAL</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>RATING</th>\n",
       "      <th>OUTPUT</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>PRED1</th>\n",
       "      <th>SENT_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TLeC</td>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "      <td>bear watch thought ua loss embarrassing</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>robrobbierobert</td>\n",
       "      <td>@octolinz16 It it counts, idk why I did either...</td>\n",
       "      <td>counts idk either never talk anymore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lovesongwriter</td>\n",
       "      <td>Hollis' death scene will hurt me severely to w...</td>\n",
       "      <td>hollis death scene hurt severely watch film wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>starkissed</td>\n",
       "      <td>@LettyA ahh ive always wanted to see rent  lov...</td>\n",
       "      <td>ahh ive always wanted see rent love soundtrack</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ljelli3166</td>\n",
       "      <td>blagh class at 8 tomorrow</td>\n",
       "      <td>blagh class tomorrow</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX             USER                                           ORIGINAL  \\\n",
       "0      0             TLeC  @caregiving I couldn't bear to watch it.  And ...   \n",
       "1      1  robrobbierobert  @octolinz16 It it counts, idk why I did either...   \n",
       "2      2   lovesongwriter  Hollis' death scene will hurt me severely to w...   \n",
       "3      3       starkissed  @LettyA ahh ive always wanted to see rent  lov...   \n",
       "4      4       Ljelli3166                         blagh class at 8 tomorrow    \n",
       "\n",
       "                                                TEXT  RATING  OUTPUT  \\\n",
       "0            bear watch thought ua loss embarrassing       1   0.162   \n",
       "1               counts idk either never talk anymore       1   0.059   \n",
       "2  hollis death scene hurt severely watch film wr...       1   0.136   \n",
       "3     ahh ive always wanted see rent love soundtrack       1   0.517   \n",
       "4                               blagh class tomorrow       0   0.296   \n",
       "\n",
       "   SENTIMENT  PRED1  SENT_SCORE  \n",
       "0          0      0           0  \n",
       "1          0      0           0  \n",
       "2          0      0           0  \n",
       "3          0      1           0  \n",
       "4          0      0           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing\n",
    "df = pd.read_csv(\"../../db/11-final-table.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56878344",
   "metadata": {},
   "source": [
    "# Setting Up Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3461b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication Successful!\n"
     ]
    }
   ],
   "source": [
    "consumer_key = 'e3quFb7yTv8RJBfJtcsH172ey'\n",
    "consumer_secret =  'SI8hYfTDQ6t90DVzk8saJlbp3Frz9eo0IWW9qCBK5JzgLj4ofa'\n",
    "access_token = '724078891384582144-KG0kZkal2PbRFiXOQva8Uatull9qVRx'\n",
    "access_token_secret = 'JWZlsm0KYB4vkjzc2CuJOkVaoym0L2Ts2lK9bBhSRMm3t'\n",
    "\n",
    "try :\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    print(\"Authentication Successful!\")\n",
    "except :\n",
    "    print(\"Authentication Failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f4d4d",
   "metadata": {},
   "source": [
    "# Class to Fetch Timeline Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92dcf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter_User():\n",
    "    def __init__(self,username,count=200):\n",
    "        self.id = api.get_user(username).id\n",
    "        self.username = username\n",
    "        self.count = count\n",
    "        self.data = None\n",
    "\n",
    "    def get_tweets(self):\n",
    "        store_tweets = api.user_timeline(self.id, count=self.count)\n",
    "        simple_list = []\n",
    "        for status in store_tweets:\n",
    "            array = [status._json[\"text\"].strip()]\n",
    "            simple_list.append(array)\n",
    "\n",
    "        self.data = pd.DataFrame(simple_list, columns=[\"TEXT\"])\n",
    "        self.data = self.data[~self.data[\"TEXT\"].str.startswith('RT')]\n",
    "        return self.data\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        id = api.get_user(self.id)\n",
    "        return id.screen_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8873ec",
   "metadata": {},
   "source": [
    "# Function to process input URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "074a445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(url) :\n",
    "    url = re.findall('http[s]?://twitter.com/(?:[a-zA-Z]|[0-9])+/status/[0-9]+', url)\n",
    "    try :\n",
    "        url = url[0].split(\"/\")\n",
    "        user_id = url[3]\n",
    "        tweet_id = url[5]\n",
    "        return (user_id, tweet_id)\n",
    "    except :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c215ed",
   "metadata": {},
   "source": [
    "# Function to Fetch Tweet/User Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8da6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_info(url) :\n",
    "    tweet = api.get_status(process_url(url)[1])\n",
    "    \n",
    "    tweet_keys = ['created_at', 'id', 'text', 'retweet_count', 'favorite_count']\n",
    "    tweet_values = []\n",
    "    for key in tweet_keys :\n",
    "        tweet_values.append(tweet._json[key])\n",
    "\n",
    "    user_keys = ['id', 'name', 'screen_name', 'url', 'description', 'followers_count', 'friends_count', 'profile_image_url_https']\n",
    "    user_values = []\n",
    "    for key in user_keys :\n",
    "        user_values.append(tweet._json['user'][key])\n",
    "\n",
    "    tweet_info = dict(zip(tweet_keys, tweet_values))\n",
    "    user_info = dict(zip(user_keys, user_values))\n",
    "    \n",
    "    return (user_info, tweet_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81abae0",
   "metadata": {},
   "source": [
    "# Functions to Preprocess Timeline Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "256db2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "sw = stopwords.words('english')\n",
    "sw.remove('not')\n",
    "\n",
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def remove_single_chars(text) :\n",
    "    array = text.split()\n",
    "    return (\" \".join([w for w in array if len(w) > 1]))\n",
    "\n",
    "def remove_stopwords(text) :\n",
    "    text = \" \".join([word for word in text.split() if word not in sw])\n",
    "    return text\n",
    "\n",
    "def apply_stemming(text) :\n",
    "    arr1 = text.split(\" \")\n",
    "    arr2 = []\n",
    "    for word in arr1 :\n",
    "        arr2.append(porter.stem(word))\n",
    "    text = \" \".join(arr2)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(sen) :\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('@[A-Za-z]+[A-Za-z0-9-_]+', '', sentence)\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    sentence = remove_single_chars(sentence)\n",
    "    sentence = apply_stemming(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841dcba",
   "metadata": {},
   "source": [
    "# Function to Calculate User Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62c8f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating(user_screen_name) :\n",
    "    user = Twitter_User(user_screen_name) \n",
    "    tweets = list(user.get_tweets().TEXT.values.tolist())\n",
    "    \n",
    "    # preprocess all tweets\n",
    "    preprocessed = []\n",
    "    for sent in tweets :\n",
    "        preprocessed.append(preprocess_text(sent))\n",
    "        \n",
    "    # tokenize and pad all tweets\n",
    "    X = tokenizer.texts_to_sequences(preprocessed)\n",
    "    X = pad_sequences(X, 48)\n",
    "    \n",
    "    # predict sentiment\n",
    "    pred = model.predict(X)\n",
    "    prediction = []\n",
    "    for value in pred :\n",
    "        prediction.append(value[1])\n",
    "        \n",
    "    # calculate rating :\n",
    "    score = 0\n",
    "    for value in prediction :\n",
    "        if value < 0.3 :\n",
    "            score = score - 1\n",
    "        elif value > 0.7 :\n",
    "            score = score + 1\n",
    "    \n",
    "    return 0 if score < 0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c470b41",
   "metadata": {},
   "source": [
    "# Fuction to Predcit Sentiment of Original Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b184d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tweet) :\n",
    "    X = tokenizer.texts_to_sequences([tweet])\n",
    "    X = pad_sequences(X, 48)\n",
    "    prediction = model.predict(X)[0][1]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c733c",
   "metadata": {},
   "source": [
    "# Calculate Sentence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dacd8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv(\"../../db/10-positive-word-score.csv\")\n",
    "neg = pd.read_csv(\"../../db/10-negative-word-score.csv\")\n",
    "lst = pos.values.tolist()\n",
    "for row in neg.values.tolist() :\n",
    "    lst.append(row)\n",
    "    \n",
    "dictionary = dict(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0378724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sent_score(text) :\n",
    "    arr = text.split(\" \")\n",
    "    score = 0\n",
    "    for word in arr :\n",
    "        if word in dictionary :\n",
    "            score = score + dictionary[word]\n",
    "            \n",
    "    return 0 if score < 0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253c5dd",
   "metadata": {},
   "source": [
    "# Fetching User & Tweet Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15d71d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://twitter.com/Eminem/status/1390053341976203268?s=20\"\n",
    "info = tweet_info(url)\n",
    "tweet = info[1]['text']\n",
    "pp_tweet = preprocess_text(tweet)\n",
    "user = info[0]['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb1e391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eminem\n",
      "\"And my thoughts are like nines cocked / Every line's obscene, pervertedest mind, got the dirtiest rhyme stocked\" 🤬… https://t.co/xoXAnRweV5\n",
      "thought like nine cock everi line obscen pervertedest mind got dirtiest rhyme stock\n"
     ]
    }
   ],
   "source": [
    "print(user)\n",
    "print(tweet)\n",
    "print(pp_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e4a1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating of 'Eminem' is POSTIVE\n"
     ]
    }
   ],
   "source": [
    "rating = calculate_rating(user)\n",
    "print(f\"Rating of \\'{user}\\' is {'POSTIVE' if rating else 'NEGATIVE'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc016849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565707"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(pp_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae9922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Major Project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
