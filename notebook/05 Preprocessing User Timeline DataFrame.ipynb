{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944b6254",
   "metadata": {},
   "source": [
    "# File 05: Preprocessing User Timeline DataFrame\n",
    "\n",
    "This file does exactly what you think it does. Preprocessing and a lot of it. Firstly we need to make sure the tweets we feed into the model to run prediction on are in the correct format. We also decided to put a limit on the number of tweets a user should have. Here we are only considering users which have tweets in the range of 100 to 200 as it should give us more accuracy while predicting its accuracy. We also remove any tweets which have less than 3 words in it. \n",
    "\n",
    "### Input Files:\n",
    "- 03-user-tweets-english-only.csv\n",
    "\n",
    "### Output Files:\n",
    "- 05-shortlisted-tweets.csv\n",
    "- 05-shortlisted-usernames.csv\n",
    "\n",
    "### Steps:\n",
    "1. loading required libraries\n",
    "1. read user timeline tweets from dataframe\n",
    "1. create functions that will preprocess the dataset\n",
    "1. preprocessing timeline tweets\n",
    "1. making a list of all usernames\n",
    "1. counting tweets by each user\n",
    "1. shortlisting users with tweet count between 100 and 200\n",
    "1. making final list of tweets and users\n",
    "1. creating dataframes\n",
    "1. saving dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61e9220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Artemis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# loading required python libraries...\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b131325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read user timeline tweets from dataframe\n",
    "df = pd.read_csv('../db/03-user-tweets-english-only.csv' )\n",
    "user = df.USER.values.tolist()\n",
    "tweet = df.TWEET.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433f466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions that will preprocess the dataset\n",
    "porter = PorterStemmer()\n",
    "sw = stopwords.words('english')\n",
    "sw.remove('not')\n",
    "\n",
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def remove_single_chars(text) :\n",
    "    array = text.split()\n",
    "    return (\" \".join([w for w in array if len(w) > 1]))\n",
    "\n",
    "def remove_stopwords(text) :\n",
    "    text = \" \".join([word for word in text.split() if word not in sw])\n",
    "    return text\n",
    "\n",
    "def preprocess_text(sen) :\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('@[A-Za-z]+[A-Za-z0-9-_]+', '', sentence)\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    sentence = remove_single_chars(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11050fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing timeline tweets...\n",
    "user = df.USER.values.tolist()\n",
    "tweet = df.TWEET.values.tolist()\n",
    "processed = []\n",
    "counts = []\n",
    "\n",
    "for index in tqdm(range(len(df))) :\n",
    "    text = preprocess_text(tweet[index])\n",
    "    processed.append(text)\n",
    "    counts.append(len(text.split()))\n",
    "\n",
    "\n",
    "temp_df = pd.DataFrame(\n",
    "    list(zip(user, tweet, processed)),\n",
    "    columns = ['USER', 'ORIGINAL', 'PROCESSED']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b510b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of all usernames\n",
    "username = []\n",
    "for x in tqdm(range(len(user))):\n",
    "    if user[x] not in username :\n",
    "        username.append(user[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f167f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting tweets by each user\n",
    "np_user = np.array(user)\n",
    "tweetcount = []\n",
    "for searchval in tqdm(username) :\n",
    "    lst = list(np.where(np_user == searchval)[0])\n",
    "    tweetcount.append(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee635b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortlisting users with tweet count between 100 and 200\n",
    "shortlist = []\n",
    "for x in tqdm(range(len(username))) :\n",
    "    if (tweetcount[x] >= 100) and (tweetcount[x] <= 200) :\n",
    "        shortlist.append(username[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0293d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making final list of tweets and users\n",
    "final_user = []\n",
    "final_tweet = []\n",
    "final_original = []\n",
    "for x in tqdm(range(len(user))) :\n",
    "    if user[x] in shortlist :\n",
    "        final_user.append(user[x])\n",
    "        final_tweet.append(processed[x])\n",
    "        final_original.append(tweet[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2411fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes\n",
    "final = pd.DataFrame(list(zip(final_user, final_tweet, final_original)), columns=['USER', 'TWEET', 'ORIGINAL'])\n",
    "username = pd.DataFrame(shortlist, columns=['USER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1baab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframes\n",
    "final.to_csv('../db/05-shortlisted-tweets.csv', index=False)\n",
    "username.to_csv('../db/05-shortlisted-usernames.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Major Project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
