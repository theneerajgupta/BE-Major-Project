{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7213ed66",
   "metadata": {},
   "source": [
    "# File 09: Prediction Sentiment Analysis on Main Dataset\n",
    "\n",
    "### Input Files:\n",
    "- model-sa/model-gpu.yaml\n",
    "- model-sa/model-weights-gpu.h5\n",
    "- model-sa/tokenizer.pickle\n",
    "- db/04-main-data.csv\n",
    "- db/08-user-rating.csv\n",
    "\n",
    "### Output Files:\n",
    "- db/09-main-prediction.csv\n",
    "\n",
    "### Steps:\n",
    "1. loading required libraries\n",
    "1. loading model with weights\n",
    "1. loading the tokenizer\n",
    "1. loading main dataset\n",
    "1. dropping unnecessary rows\n",
    "1. prepping input for prediction\n",
    "1. predicting sentiment\n",
    "1. fetching user rating\n",
    "1. saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b715a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# loading required libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.models import model_from_yaml\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6be4ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artemis\\.conda\\envs\\project\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 48, 128)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 48, 196)           255584    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 48, 196)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 196)               308896    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 1,204,874\n",
      "Trainable params: 1,204,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading model with weights\n",
    "def load_model(model, weight) :\n",
    "    with open(model, 'r') as file:\n",
    "        yaml_model = file.read()\n",
    "\n",
    "    model = tf.keras.models.model_from_yaml(yaml_model)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.load_weights(weight)\n",
    "    return model\n",
    "\n",
    "model = load_model('../sentiment-analysis-model/model-gpu.yaml', '../sentiment-analysis-model/weights-gpu.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4edeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer\n",
    "with open('../sentiment-analysis-model/tokenizer.pickle', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df4d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading main dataset\n",
    "df = pd.read_csv(\"../../db/04-main-data.csv\")\n",
    "rating = pd.read_csv(\"../../db/08-user-rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c887754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11677/11677 [00:18<00:00, 633.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# dropping unnecessary rows\n",
    "df_user = df.USER.values.tolist()\n",
    "rating_user = rating.USER.values.tolist()\n",
    "todrop_user = list(set(df_user) - set(rating_user))\n",
    "for name in tqdm(todrop_user) :\n",
    "    index = df.loc[df.USER == name].index\n",
    "    df.drop(index, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613cd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepping input for prediction\n",
    "df.TEXT=df.TEXT.astype(str)\n",
    "X = tokenizer.texts_to_sequences(df['TEXT'].values)\n",
    "X = pad_sequences(X, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8193c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting sentiment\n",
    "pred1 = []\n",
    "temp = model.predict(X)\n",
    "polarity = [round(value[1], 3) for value in temp]\n",
    "for value in polarity :\n",
    "    pred1.append(0 if value<0.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9aa1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching user rating\n",
    "username = df.USER.values.tolist()\n",
    "user_rating = []\n",
    "for x in range(len(username)) :\n",
    "    user_rating.append(int(rating.loc[rating['USER'] == username[x]]['RATING']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9476d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>ORIGINAL</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>OUTPUT</th>\n",
       "      <th>PRED1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TLeC</td>\n",
       "      <td>1</td>\n",
       "      <td>bear watch thought ua loss embarrass</td>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robrobbierobert</td>\n",
       "      <td>1</td>\n",
       "      <td>count idk either never talk anymor</td>\n",
       "      <td>@octolinz16 It it counts, idk why I did either...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lovesongwriter</td>\n",
       "      <td>1</td>\n",
       "      <td>holli death scene hurt sever watch film wri di...</td>\n",
       "      <td>Hollis' death scene will hurt me severely to w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>starkissed</td>\n",
       "      <td>1</td>\n",
       "      <td>ahh ive alway want see rent love soundtrack</td>\n",
       "      <td>@LettyA ahh ive always wanted to see rent  lov...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ljelli3166</td>\n",
       "      <td>1</td>\n",
       "      <td>blagh class tomorrow</td>\n",
       "      <td>blagh class at 8 tomorrow</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              USER  RATING                                               TEXT  \\\n",
       "0             TLeC       1               bear watch thought ua loss embarrass   \n",
       "1  robrobbierobert       1                 count idk either never talk anymor   \n",
       "2   lovesongwriter       1  holli death scene hurt sever watch film wri di...   \n",
       "3       starkissed       1        ahh ive alway want see rent love soundtrack   \n",
       "4       Ljelli3166       1                               blagh class tomorrow   \n",
       "\n",
       "                                            ORIGINAL  SENTIMENT  OUTPUT  PRED1  \n",
       "0  @caregiving I couldn't bear to watch it.  And ...          0   0.428      0  \n",
       "1  @octolinz16 It it counts, idk why I did either...          0   0.137      0  \n",
       "2  Hollis' death scene will hurt me severely to w...          0   0.034      0  \n",
       "3  @LettyA ahh ive always wanted to see rent  lov...          0   0.466      0  \n",
       "4                         blagh class at 8 tomorrow           0   0.275      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving output\n",
    "final = pd.DataFrame(\n",
    "    list(zip(\n",
    "        df.USER.values.tolist(),\n",
    "        user_rating,\n",
    "        df.TEXT.values.tolist(),\n",
    "        df.ORIGINAL.values.tolist(),\n",
    "        df.SENTIMENT.values.tolist(),\n",
    "        polarity,\n",
    "        pred1)),\n",
    "    columns = [ 'USER', 'RATING', 'TEXT', 'ORIGINAL', 'SENTIMENT', 'OUTPUT', 'PRED1' ]\n",
    ")\n",
    "# final.to_csv(\"../db/09-phase-1-prediction.csv\", index=False)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a80773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Results:\n",
      "Accuracy: 0.7408503348388101\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(final.SENTIMENT.values.tolist(), final.PRED1.values.tolist())\n",
    "acc = accuracy_score(final.SENTIMENT.values.tolist(), final.PRED1.values.tolist())\n",
    "print(\"Printing Results:\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea6e39a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cecb8f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      3084\n",
      "           1       0.75      0.75      0.75      3337\n",
      "\n",
      "    accuracy                           0.74      6421\n",
      "   macro avg       0.74      0.74      0.74      6421\n",
      "weighted avg       0.74      0.74      0.74      6421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(final.SENTIMENT.values.tolist(), final.PRED1.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e8a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Major Project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
